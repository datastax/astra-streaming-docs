= Externally Exposed Astra Streaming Metrics for Integration

Because Astra Streaming is a software-as-a-service product, not all Apache Pulsar metrics (https://pulsar.apache.org/docs/reference-metrics/[Pulsar Metrics Reference]) are exposed for external integration purposes. At a high level, Astra Streaming only exposes metrics that are related to namespaces. Other metrics that are not directly namespace related are not exposed externally, such as the Bookkeeper ledger and journal metrics and Zookeeper metrics.

In the following sections, we’ll explore each of the Astra Streaming metrics categories that are available for external integration, and recommended metrics for external integration.

== Pulsar raw metrics

If you're just looking for a complete reference for Pulsar metrics, they are available below.

Namespace metrics:

https://pulsar.apache.org/docs/reference-metrics/#namespace-metrics

Topic metrics:

https://pulsar.apache.org/docs/reference-metrics/#topic-metrics

== {product_name} metrics

=== Namespace and topic metrics
Astra Streaming exposes both namespace and topic level metrics.
Namespace metrics can always be inferred from corresponding topic metrics via metrics aggregation.

The following table lists recommended namespace and/or topic metrics as a starting point.

[%header,format=csv,cols="2,1,1,3"]
|===
include::example$namespace-topic-metrics.csv[]
|===

=== Replication Metrics
When geo-replication is enabled for a particular namespace, a subset of namespace metrics is available specifically for geo-replication purposes. Below is the list of recommended geo-replication metrics as a starting point.

[%header,format=csv,cols="2,1,1,3"]
|===
include::example$replication-metrics.csv[]
|===

=== Subscription metrics
The following table gives the list of recommended subscription metrics as a starting point.

[%header,format=csv,cols="2,1,3"]
|===
include::example$subscription-metrics.csv[]
|===

=== Function Metrics

The following table gives the list of recommended function metrics as a starting point. This is only relevant when Pulsar functions are deployed in Astra Streaming.

[%header,format=csv,cols="2,1,3"]
|===
include::example$function-metrics.csv[]
|===

=== Source connector metrics
The following table gives the list of recommended source connector metrics as a starting point. This is only relevant when Pulsar source connectors are deployed in Astra Streaming.

[%header,format=csv,cols="2,1,3"]
|===
include::example$source-connector-metrics.csv[]
|===

=== Sink connector metrics
The following table gives the list of recommended source connector metrics as a starting point. This is only relevant when Pulsar sink connectors are deployed in Astra Streaming.
[%header,format=csv,cols="2,1,3"]
|===
include::example$sink-connector-metrics.csv[]
|===

== Aggregate Astra Streaming Metrics

Each externally exposed raw Astra Streaming metric is reported at a very low level, at each individual server instance (the `exported_instance` label) and each topic partition (the `topic` label). The same raw metrics could come from multiple server instances. From a {product_name} user’s perspective, the direct monitoring of raw metrics is not really useful. Raw metrics need to be aggregated first - for example, by averaging or summing the raw metrics over a period of time.

Below is an example of a raw metric for the Pulsar message backlog (pulsar_msg_backlog) scraped from an Astra Streaming cluster located in the GCP US Central region:

.Show raw metric for Pulsar message backlog:
[%collapsible]
====
....
pulsar_msg_backlog{app="pulsar", cluster="pulsar-gcp-uscentral1", component="broker", controller_revision_hash="pulsar-gcp-uscentral1-broker-<hash>f", exported_instance="<ip>:<port>", exported_job="broker", helm_release_name="astraproduction-gcp-pulsar-uscentral1", instance="prometheus-gcp-uscentral1.streaming.datastax.com:443", job="astra-pulsar-metrics-msgenrich", kubernetes_namespace="pulsar", kubernetes_pod_name="pulsar-gcp-uscentral1-broker-3", namespace="msgenrich/testns", prometheus="pulsar/astraproduction-gcp-pulsar-prometheus", prometheus_replica="prometheus-astraproduction-gcp-pulsar-prometheus-0", pulsar_cluster_dns="gcp-uscentral1.streaming.datastax.com", release="astraproduction-gcp-pulsar-uscentral1", statefulset_kubernetes_io_pod_name="pulsar-gcp-uscentral1-broker-3", topic="persistent://msgenrich/testns/raw-partition-0"}
....
====

To make raw metrics like this useful for end users, we recommend the following guidelines when aggregating raw metrics:

. Aggregate metrics to at least the parent topic level, instead of at the partition level. In Pulsar, end user applications only deal with messages at the parent topic level (but internally, Pulsar is handling message processing at the partition level).
. Exclude reported metrics that are associated with Astra Streaming’s system namespaces and topics. These namespaces and topics normally have a name starting with ++__++ (two underscores). For example, when Pulsar’s Kafka protocol handler is enabled (via S4K integration), a system namespace ++__kafka++ is created with one system topic within called ++__transaction_producer_state++.
Do NOT aggregate metrics with the Astra Streaming PAYG option, since one cluster may be shared among multiple organizations. For more, see xref:astream-limits.adoc[Cluster Limits].

=== PromQL query patterns

Prometheus provides a powerful but easy-to-use query language called PromQL for selecting and aggregating time series data in real time. PromQL syntax is beyond this document's scope, but the https://prometheus.io/docs/prometheus/latest/querying/basics/[Prometheus documentation] is a great place to start.

In the rest of this section, we’ll recommend some PromQL query patterns for aggregating raw Astra Streaming metrics.
These examples use one Astra Streaming raw metric, pulsar_msg_backlog, as an example for illustrative purposes.
We aggregate messages at the parent topic level or above, and exclude system topics per our recommendations above.
We filter out system messages with the pattern +{topic !~ ".*__.*"}+.
This PromQL pattern filters out messages when their topic labels do not include +__+.
This works because Pulsar system topics usually have ++__++ as the topic or namespace name prefix (e.g. persistent://<tenant>/++__++kafka/__consumer_offsets_partition_0).
This pattern assumes that the user applications don’t also have namespaces and topics with +__+ as part of the names, or they will be filtered as well.

Pattern 1: Get the total message backlog of a specific parent topic, excluding system topics.
"$ptopic” is a (Grafana dashboard) variable that represents a specific parent topic.
[source,psql]
----
sum(pulsar_msg_backlog{topic=~$ptopic, topic !~ ".*__.*"})
----

Pattern 2: Get the total message backlog of a specific namespace, excluding system topics.
“$namespace” is a (Grafana dashboard) variable that represents a specific namespace.
[source,psql]
----
sum(pulsar_msg_backlog{namespace=~”$namespace”, topic !~ ".*__.*"})
----

Pattern 3: Get the total message backlog of a tenant, excluding system topics.
"$tenant” is a (Grafana dashboard) variable that represents a specific tenant.
[source,psql]
----
sum(pulsar_msg_backlog{namespace=~”$tenant.+”, topic !~ ".*__.*"})
----

Pattern 4: Get the total message backlog of each topic within a specific namespace, excluding system topics.
[source,psql]
----
sum by(topic) (pulsar_msg_backlog{namespace=~”$namespace”, topic !~ ".*__.*"})
----

Pattern 5: Get the top 10 message backlog by topic within a specific namespace, excluding system topics.
[source,psql]
----
topk by(topic) (10, sum(pulsar_msg_backlog{namespace=~”$namespace”, topic !~ ".*__.*"})
----

== Metrics to be alerted
Most of the exposed Astra Streaming metrics are for informational purposes only and in most cases the metrics values are just reflecting the application workload characteristics. For example, message rate or throughput are common examples of such metrics.

There are, however, several metrics that need special attention when we see an increasing number of their values. Among the exposed Astra Streaming metrics, these metrics are:
.Metrics for alerting
[%header,format=csv,cols="2,2,1,3"]
|===
include::example$alert-metrics.csv[]
|===

=== Alerting rules
In a perfect world, these metrics should always stay at 0, but in reality, these metrics will increase when the application workload becomes heavier.
If your system is behaving correctly, these metrics should go down when the application workload drops.

A simple way to trigger an alert on these metrics is to set a threshold which triggers an alert when the metric exceeds it. However, this will probably cause false alarms during workload spikes.

A better approach is calculating the metrics' increase rate over a period of time (e.g. 1 hour) and setting a threshold on the rate of increase.
For example, if the average message backlog increase rate exceeds a threshold, an alert is triggered.

The actual threshold values for these metrics is highly dependent on each application’s workload and requirements, but the values should be relatively large positive numbers, e.g. several hundreds or several thousands.
Otherwise, they may trigger too many false alarms.

== Grafana dashboards for Astra Streaming metrics

DataStax has built Grafana dashboards around core message processing for the exposed Astra Streaming metrics.
The dashboards can be found https://github.com/datastax/astra-streaming-examples/tree/master/grafana-dashboards[on GitHub^]{external-link-icon}.

== Overview Dashboard

The https://github.com/datastax/astra-streaming-examples/blob/master/grafana-dashboards/as-overview.json[overview dashboard^]{external-link-icon} has three major sections which display the highest aggregation level - tenant level, tenant level with namespace level separation, and the variable section, where you can choose a cluster and a tenant.

=== Tenant overview
Overview displays the aggregated total metrics values summarized at the tenant level. The following metrics are included:

.Tenant overview
[%collapsible]
====
Total number of namespaces +
Total number of topics +
Total number of producers +
Total number of consumers +
Total number of subscriptions +
Total message storage size (logical) - before replication +
Total message storage size -  after replication +
Total message size offloaded to a tiered storage +
Total message backlog +
Total message replication backlog +
Total hourly incoming message number +
Total hourly incoming message average size
====

=== Messaging
Messaging displays the time series metrics chart summarized at the tenant level. The following metrics are included:

.Messaging
[%collapsible]
====
Total incoming message rate (msg/s) of the tenant divided by namespaces +
Total outgoing message rate (msg/s) of the tenant divided by namespaces +
Total incoming message throughput (byte/s) of the tenant divided by namespaces +
Total outgoing message throughput (byte/s) of the tenant divided by namespaces +
Total message backlog of the tenant divided by namespaces +
Total message storage size of the tenant divided by namespaces +
Total Message replication backlog rate (msg/s) divided of the tenant divided by remote clusters +
Total Producer/Consumer/Subscription count of the tenant +
Total unacknowledged messages of the tenant divided by namespaces +
Total message drop rate of the tenant divided by namespaces +
Total incoming message replication rate (msg/s) of the tenant divided by remote clusters +
Total outgoing message replication rate (msg/s) of the tenant divided by remote clusters +
Total incoming message replication throughput (byte/s) of the tenant divided by remote clusters +
Total outgoing message replication throughput (byte/s) of the tenant divided by remote clusters +
Top 10 topics of the tenant by message backlog +
Top 10 topics of the tenant by message replication backlog +
Top 10 topics of the tenant by unacknowledged message +
Top 10 topics of the tenant by message storage size
====

== Namespace Dashboard
The https://github.com/datastax/astra-streaming-examples/blob/master/grafana-dashboards/as-namespace.json[namespace dashboard^]{external-link-icon} aggregates metrics at the namespace level. In the variable section, you can choose a cluster, tenant, and namespace.

=== Namespace overview
Namespace overview displays the aggregated total metrics values summarized at the namespace level.

.Namespace overview
[%collapsible]
====
Total number of topics +
Total number of producers +
Total number of consumers +
Total number of subscriptions +
Total message backlog +
Total message replication backlog +
Total message storage size +
Total message size offloaded to a tiered storage +
Total hourly incoming message number +
Total hourly incoming message average size
====

=== Messaging
Messaging displays the time series metrics chart summarized at the namespace level with an additional level of detail (topics).

.Messaging
[%collapsible]
====
Total incoming message rate (msg/s) of the namespace divided by topics +
Total outgoing message rate (msg/s) of the namespace divided by topics +
Total incoming message throughput (byte/s) of the namespace divided by topics +
Total outgoing message throughput (byte/s) of the namespace divided by topics +
Total message backlog of the namespace divided by topics +
Total unacknowledged messages of the namespace divided by topics +
Total message drop rate of the namespace divided by topics +
Total Producer/Consumer/Subscription count of the namespace divided by topics
====

=== Georeplication
Geo-replication displays the time series metrics chart summarized at the namespace level with an additional level of detail (remote clusters).

.Georeplication
[%collapsible]
====
Total incoming replication rate (msg/s) to the namespace divided by remote clusters +
Total outgoing replication rate (msg/s) from the namespace divided by remote clusters +
Total incoming replication throughput (byte/s) to the namespace divided by remote clusters +
Total outgoing replication throughput (byte/s) from the namespace divided by remote clusters +
Total (outgoing) message replication backlog from the namespace divided by remote clusters
====

== Topic dashboard
The https://github.com/datastax/astra-streaming-examples/blob/master/grafana-dashboards/as-topic.json[topic dashboard^]{external-link-icon} aggregates metrics at the topic level. In the variable section, you can choose a cluster, tenant, and namespace, and topic.
This dashboard analyzes metrics at the parent topic level, not at the partition level.

=== Topic overview
Overview displays the aggregated total metrics values summarized at the topic level.

.Topic overview
[%collapsible]
====
Total number of producers +
Total number of consumers +
Total number of subscriptions +
Total message backlog +
Total message replication backlog +
Total message storage size -  after replication +
Total message size offloaded to a tiered storage +
Total hourly incoming message number +
Total hourly incoming message average size
====

=== Messaging
Messaging displays the time series metrics chart summarized at the topic level with an additional level of detail (partitions).

.Messaging
[%collapsible]
====
Total incoming message rate (msg/s) of the topic divided by partitions +
Total outgoing message rate (msg/s) of the topic divided by partitions +
Total incoming message throughput (bytes/s) of the topic divided by partitions +
Total outgoing message throughput (bytes/s) of the topic divided by partitions +
Total message backlog of the topic divided by partitions +
Total unacknowledged messages of the topic divided by partitions
====

=== Subscription
Subscription displays the time series metrics chart summarized at the subscription level with an additional level of detail (by individual subscriptions).

.Subscription
[%collapsible]
====
Total subscription message backlog divided by individual subscriptions +
Total subscription message backlog with no delay divided by individual subscriptions +
Total subscription unacknowledged messages divided by individual subscriptions +
Total subscription delayed messages divided by individual subscriptions +
Total subscription message dispatch rate (msg/s) divided by individual subscriptions +
Total subscription message throughput rate (byte/s) divided by individual subscriptions +
Total subscription message acknowledgement rate (msg/s) divided by individual subscriptions +
Total subscription message redelivery rate (msg/s) divided by individual subscriptions +
Total subscription message expired rate (msg/s) divided by individual subscriptions +
Total subscription message dropped rate (msg/s) divided by individual subscriptions +
Total subscription messages processed by EntryFilter, divided by individual subscriptions +
Total subscription messages accepted by EntryFilter, divided by individual subscriptions +
Total subscription messages rejected by EntryFilter, divided by individual subscriptions +
Total subscription messages rescheduled by EntryFilter, divided by individual subscriptions
====

=== Georeplication

Georeplication displays the time series metrics chart summarized at the topic level with an additional level of detail (remote clusters).

.Georeplication
[%collapsible]
====
Incoming replication rate (msg/s) to the topic divided by remote clusters +
Outgoing replication rate (msg/s) from the topic divided by remote clusters +
Incoming replication throughput (byte/s) to the topic divided by remote clusters +
Outgoing replication throughput (byte/s) from the topic divided by remote clusters +
Total (outgoing) message replication backlog from the topic divided by remote clusters
====

== What's next?

To scrape Astra Streaming metrics in Kubernetes with an external Prometheus server, see xref:monitoring-integration.adoc[].

