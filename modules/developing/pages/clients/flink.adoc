= Apache Flink

Apache Flink is an open source stream processing framework with powerful stream- and batch-processing capabilities.
{product_name} offers a fully managed Apache Flink service enabling you to build and run streaming applications without having to manage the underlying infrastructure.

== Connect to Flink

The {product_name} Flink endpoint is currently available at `https://pulsar-aws-useast2.api.dev.streaming.datastax.com/flink/api/`.
To connect, you'll need both an AstraCS token and a Pulsar token.

For more on generating the Astra and Pulsar JWT tokens, see xref:getting-started:index.adoc[].
For more on the differences between the Astra and Pulsar tokens, see xref:operations:onboarding-faq.adoc#secure-sign-on-roles-and-permissions[].
For more on setting up your Pulsar binaries, see xref:configure-pulsar-env.adoc[].

. Set your environmental variables to follow along with the examples in this section:
+
[source,bash]
----
export token=AstraCS:xxxx
export tenant=flink-tenant
export PULSAR_CLIENT_CONF=$(realpath client.conf)
export PULSAR_TOKEN=eyXXXX
export endpoint="https://pulsar-aws-useast2.api.dev.streaming.datastax.com/flink/api/jobs/$tenant"
----

. Activate Flink in {product_name} with a POST request:
+
[tabs]
====
Curl::
+
--
[source,bash]
----
curl -H "Content-Type: application/json" -H "Authorization: Bearer $PULSAR_TOKEN" -X POST "https://pulsar-aws-useast2.api.dev.streaming.datastax.com/flink/$tenant"
----
--

Result::
+
--
[source,]
----
{"status":true}%
----
--
====

. Test connectivity by issuing a GET request for a list of your current Flink jobs:
+
[tabs]
====
Curl::
+
--
[source,bash]
----
curl -H "Content-Type: application/json" -H "Authorization: Bearer $token" "https://pulsar-aws-useast2.api.dev.streaming.datastax.com/flink/api/jobs/$tenant"
----
--

Result::
+
--
[source,bash]
----
[]%  //empty array
----
--
====

Now that you've connected {product_name} and Flink, you can start managing Flink jobs.

== Create a Flink job

A Flink *job* is a collection of one or more Flink applications that are submitted to a Flink cluster for execution. In a Flink job, data is typically ingested from various sources such as Kafka, HDFS, or databases. The data is then processed using Flink's high-level APIs or low-level operators, which provide a wide range of transformations and operations for data manipulation, filtering, aggregation, and analytics.

Overall, a Flink job enables you to process and analyze large-scale data sets efficiently, with low-latency and high throughput, making it suitable for various use cases such as real-time analytics, event-driven applications, data pipelines, and ETL (Extract, Transform, Load) processes.

A little more setup is required to create a Flink job.

It is VERY important that on the Pulsar side (in {product_name}, in this case) you have pre-created both the input and output topics, and that all the topics have a schema that is compatible with the Flink table schema (in this case, a JSON schema).

. First, add more environment variables to complete this example:
+
[source,bash]
----
PULSAR_CLIENT_CONF=$PULSAR_HOME/conf/clienf.conf
inputTopic=flink-tenant/flink/persons
outputTopic=flink-tenant/flink/persons-output
PULSAR_HOME=$(pwd)
ADMINCMD=$PULSAR_HOME/bin/pulsar-admin
CLIENTCMD=$PULSAR_HOME/bin/pulsar-client
$ADMINCMD topics delete-partitioned-topic $inputTopic
$ADMINCMD topics delete-partitioned-topic $outputTopic
$ADMINCMD topics create-partitioned-topic -p 2 $inputTopic
$ADMINCMD topics create-partitioned-topic -p 2 $outputTopic
----

. Produce data to set a JSON schema on the "persons" (`$inputTopic`) and "persons-output" (`$outputTopic`) topics.
First, we'll produce messages to the "persons" (`$inputTopic`) topic:
+
[tabs]
====
Curl::
+
--
[source,bash]
----
$CLIENTCMD produce -k family-1 -m "{\"name\":\"giovanni\"}","{\"name\":\"enrico\"}","{\"name\":\"giovanni\"}" -vs 'json:{"type": "record","namespace":"com.example","name":"Person","fields":[{"name":"name","type":"string"}]}'  $inputTopic
----
--

Result::
+
--
[source,bash]
----
...
2023-05-24T17:35:21,391-0400 [main] INFO  org.apache.pulsar.client.cli.PulsarClientTool - 3 messages successfully produced
----
--
====
+
.. We produced three messages with JSON schema to the "persons" (`$inputTopic) topic. Let's confirm our schema looks as expected:
+
[tabs]
====
Curl::
+
--
[source,bash]
----
$ADMINCMD schemas get $inputTopic
----
--

Result::
+
--
[source,json]
----
{
  "version": 0,
  "schemaInfo": {
    "name": "persons",
    "schema": {
      "type": "record",
      "namespace": "com.example",
      "name": "Person",
      "fields": [
        {
          "name": "name",
          "type": "string"
        }
      ]
    },
    "type": "JSON",
    "timestamp": 1684964118894,
    "properties": {}
  }
}
----
--
====

.. Now, we'll produce messages to the "persons-output" (`$outputTopic`) topic:
+
[tabs]
====
Curl::
+
--
[source,bash]
----
$CLIENTCMD produce -m "{\"name\":\"init\"}" -vs 'json:{"type": "record","namespace":"com.example","name":"Person","fields":[{"name":"name","type":"string"}]}' $outputTopic
----
--

Result::
+
--
[source,bash]
----
...
2023-05-24T17:55:34,707-0400 [main] INFO  org.apache.pulsar.client.cli.PulsarClientTool - 1 messages successfully produced
----
--
====
+
.. We produced a message with JSON schema to the "persons-output" (`$outputTopic) topic. Let's confirm our schema looks as expected:
+
[tabs]
====
Curl::
+
--
[source,bash]
----
$ADMINCMD schemas get $outputTopic
----
--

Result::
+
--
[source,json]
----
{
  "version": 0,
  "schemaInfo": {
    "name": "persons-output",
    "schema": {
      "type": "record",
      "namespace": "com.example",
      "name": "Person",
      "fields": [
        {
          "name": "name",
          "type": "string"
        }
      ]
    },
    "type": "JSON",
    "timestamp": 1684965332419,
    "properties": {}
  }
}
----
--
====
+
. Now that you have set up your environment and created two topics with JSON schemas, you can create the Flink job.
Creating a Flink job consists of creating the JSON payload that defines the Flink job, and then POSTing that JSON payload to the {product_name} endpoint.
+
[NOTE]
====
This example uses the jq command-line JSON processor to format the JSON payload. For more, see https://stedolan.github.io/jq/[jq^]{external-link-icon}.
====
+
This example creates a Flink job that reads from the "persons" topic and writes to the "persons-output" topic, and POSTs the JSON to the {product_name} endpoint.
+
The JSON payload contains the definition of the Flink job:

* create the tables involved in the query (`"tableName": "input"`)
* specifying the output table (`"outputTable": "output"`)
* specifies the query (`"selectQuery": "select input.name from flink.input as input"`)

The POST request to the jobs/$tenant endpoint creates the actual Flink job.
[tabs]
====
Console::
+
--
[source,bash]
----
cat > create-job-persons.json << EndOfMessage
{
  "parallelism": 1,
  "outputTable": "output",
  "createTableSpecs": [
{
 "tableName": "input",
 "format": "json",
 "topic": "$inputTopic",
 "columns": ["name string"]
}
],
  "selectQuery": "select input.name from flink.input as input"
}
EndOfMessage
cat create-job-persons.json | jq
endpoint="https://pulsar-aws-useast2.api.dev.streaming.datastax.com/flink/api/jobs/$tenant"
curl -H "Content-Type: application/json" -H "Authorization: Bearer $token" -X POST  --data @create-job-persons.json $endpoint -v -o -

{
  "parallelism": 1,
  "outputTable": "output",
  "createTableSpecs": [
    {
      "tableName": "input",
      "format": "json",
      "topic": "flink-tenant/flink/persons",
      "columns": [
        "name string"
      ]
    }
  ],
  "selectQuery": "select input.name from flink.input as input"
}
----
--

Result::
+
--
[source,]
----
{"specs":{"name":"j-flink-tenant-vwnrwv","outputTable":"output","selectQuery":"select input.name from flink.input as input","createTableSpecs":[{"tableName":"input","columns":["name string"],"topic":"flink-tenant/flink/persons","format":"json"}],"parallelism":1},"status":{"lifecycleState":"CREATED"}}%
----
--
====

Nice, you've created a Flink job! Next we'll check its status, view its logs, and delete it.

=== Check a Flink job's status
Issue a GET request to `https://pulsar-aws-useast2.api.dev.streaming.datastax.com/flink/api/jobs/$tenant/$jobName`:
[tabs]
====
Curl::
+
--
[source,bash]
----
curl -v -H "Content-Type: application/json" -H "Authorization: Bearer $token" $endpoint/$jobName
----
--

Result::
+
--
[source,json]
----
{
  "specs": {
    "name": "j-flink-tenant-zicjos",
    "outputTable": "output",
    "selectQuery": "select input.name from flink.input as input",
    "createTableSpecs": [
      {
        "tableName": "input",
        "columns": [
          "name string"
        ],
        "topic": "flink-tenant/flink/persons",
        "format": "json"
      }
    ],
    "parallelism": 1
  },
  "status": {
    "state": "RECONCILING",
    "error": "{\"type\":\"org.apache.flink.kubernetes.operator.exception.DeploymentFailedException\",\"message\":\"back-off 5m0s restarting failed container=flink-main-container pod=j-flink-tenant-zicjos-84c46c749-pmbfw_fl-flink-tenant(bcaf73fd-0db7-4a5d-897b-63acad0822c3)\",\"additionalMetadata\":{\"reason\":\"CrashLoopBackOff\"},\"throwableList\":[]}",
    "lifecycleState": "DEPLOYED"
  }
}
----
--
====

== View a Flink job's logs

To tail a Flink job's logs:
[tabs]
====
Curl::
+
--
[source,bash]
----
curl -H "Content-Type: application/json" -H "Authorization: Bearer $token" "https://pulsar-aws-useast2.api.dev.streaming.datastax.com/flink/logs/$tenant/$jobName/jobmanager?tail=true"
----
--

Result::
+
--
[source,bash]
----
no default tenant admin role is defined
----
--
====

To tail a Flink function worker's logs:
[tabs]
====
Curl::
+
--
[source,bash]
----
curl -H "Content-Type: application/json" -H "Authorization: Bearer $token" "https://pulsar-aws-useast2.api.dev.streaming.datastax.com/flink/logs/$tenant/$jobName/jobmanager?tail=true"
----
--

Result::
+
--
[source,bash]
----
no default tenant admin role is defined
----
--
====

== Delete a Flink job

To delete the job we queried above (`j-flink-tenant-zicjos`), issue a DELETE request to `https://pulsar-aws-useast2.api.dev.streaming.datastax.com/flink/api/jobs/$tenant/j-flink-tenant-zicjos`:
[tabs]
====
Curl::
+
--
[source,bash]
----
curl -v -H "Content-Type: application/json" -H "Authorization: Bearer $token" -X DELETE $endpoint/$jobName
----
--

Result::
+
--
[source,bash]
----
> DELETE /flink/api/jobs/flink-tenant/j-flink-tenant-zicjos HTTP/1.1
> Host: pulsar-aws-useast2.api.dev.streaming.datastax.com
> User-Agent: curl/7.79.1
> Accept: */*
> Content-Type: application/json
> Authorization: Bearer AstraCS:xxxx
>
* Mark bundle as not supporting multiuse
< HTTP/1.1 200 OK
----
--
====

== Alternate method: Test a Flink query with a consumer

You can create a consumer to check the status of the Flink job. The consumer will read from the "flink-tenant/flink/$jobName" topic, which is created when you create the Flink job.

. Create a consumer to read from the "flink-tenant/flink/$jobName" topic:
[tabs]
====
Console::
+
--
[source,bash]
----
cat > create-job-persons.json << EndOfMessage
{
  "parallelism": 1,
  "createTableSpecs": [
{
 "tableName": "input", 
 "format": "json",
 "topic": "$inputTopic",
 "columns": ["name string"]  
}
],
  "selectQuery": "select * from flink.input as input"
}
EndOfMessage
cat create-job-persons.json | jq
endpoint="https://pulsar-aws-useast2.api.dev.streaming.datastax.com/flink/api/previews/$tenant"
response=$(curl -H "Content-Type: application/json" -H "Authorization: Bearer $token" -X POST  --data @create-job-persons.json $endpoint -v -o -)
outputTopic=$(echo "$response" | jq -c '.specs.outputTable' | tr -d '`' | tr -d '"' | awk -F '\.' '{print $2}')
$CLIENTCMD consume -s test -p Earliest $tenant/flink/$outputTopic
----
--

Result::
+
--
[source,]
----
2023-05-25T10:03:22,891-0400 [pulsar-client-io-1-1] INFO  org.apache.pulsar.client.impl.ConsumerImpl - [flink-tenant/flink/temp-02615cee-7263-4d21-8761-0fba2acb9ac6][test] Subscribed to topic on pulsar-aws-useast2.dev.streaming.datastax.com/3.18.199.190:6651 -- consumer: 0
----
--
====

. In the {astra_ui}, you will see the created topics and a consumer.

== What's next?

